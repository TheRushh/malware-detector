import pandas as pd
import numpy as np
import math
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report 
from sklearn.feature_selection import VarianceThreshold

# Function to import dataset
def importdata(path):
    #Read from CSV
    data = pd.read_csv(path)
    print ("Dataset Lenght: ", len(data)) 
    print ("Dataset Shape: ", data.shape)
    print ("Dataset: \n", data.head())
    return data


# Function to split dataset
def splitdataset(data):
    # Split Dataset
    X = data.values[:, 1:] 
    Y = data.values[:, 0] 

    # Spliting the dataset into train and test 
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0) 
    # print (X, Y, X_train, X_test, y_train, y_test)
    return X, Y, X_train, X_test, y_train, y_test


# Function to perform training with giniIndex
def train_using_gini(X_train, y_train):
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", random_state = 0)
    # Performing training 
    clf_gini.fit(X_train, y_train) 
    # print(clf_gini)
    return clf_gini


# Function to perform training with entropy. 
def train_using_entropy(X_train, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier(criterion = "entropy", random_state = 0) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy 


# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("\nConfusion Matrix: \n", 
    confusion_matrix(y_test, y_pred)) 
      
    print ("\nAccuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("\nReport : \n", 
    classification_report(y_test, y_pred))


def variance_threshold_selector(data, threshold=0.5):
    selector = VarianceThreshold(threshold)
    selector.fit(data)
    return data[data.columns[selector.get_support(indices=True)]]


# Driver code 
def main(): 
    # Building Phase 
    data = importdata('dataset_malwares.csv') 
    X, Y, X_train, X_test, y_train, y_test = splitdataset(data) 
    clf_gini = train_using_gini(X_train, y_train) 
    clf_entropy = train_using_entropy(X_train, y_train) 
    
    # Operational Phase 
    
    # Prediction using gini 
    print("Results Using Gini Index:") 
    y_pred_gini = prediction(X_test, clf_gini) 
    print('Predicted Values: ', y_pred_gini)
    cal_accuracy(y_test, y_pred_gini) 
    
    # Prediction using entropy
    print("Results Using Entropy:") 
    y_pred_entropy = prediction(X_test, clf_entropy) 
    print('Predicted Values: ', y_pred_entropy)
    cal_accuracy(y_test, y_pred_entropy) 

    testdata = importdata('dataset_test.csv')
    # print (testdata.values[0:-1, 1:-1])

    predict_gini = prediction(testdata.values[:,1:],clf_gini)
    predict_entropy = prediction(testdata.values[:,1:],clf_entropy)

    print('\nResults using Gini:\n')
    for i in range (len(testdata)):
        if (predict_gini[i]):
            print (testdata.values[i,0], ': Malware')
        else:
            print (testdata.values[i,0], ': Genuine')

    print('\nResults using Entropy:\n')
    for i in range (len(testdata)):
        if (predict_entropy[i]):
            print (testdata.values[i,0], ': Malware')
        else:
            print (testdata.values[i,0], ': Genuine')



    # for i in range (len(testdata)):
    #     print (testdata.values[i,0], predict[i])



# Calling main function
if __name__=='__main__':
    main()
# virus = 0
# genuine = 0
# for type in data['Type']:
#     # print (type)
#     if type=='Virus':
#         virus+=1
#     else:
#         genuine+=1

# print(virus, genuine)
# entropy = - (virus/(virus+genuine)*math.log(virus/(virus+genuine),2) + genuine/(virus+genuine)*math.log(genuine/(virus+genuine),2))
# print (entropy)
    
